{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5049b4a6",
   "metadata": {},
   "source": [
    "# Object Classification Using Convolutional Neural Networks\n",
    "## Pen vs. Pencil Classification\n",
    "\n",
    "**Objective:** Develop a CNN model that automatically classifies images into two categories: pen and pencil.\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand the fundamentals of image classification using CNNs\n",
    "- Prepare and preprocess an image dataset for deep learning\n",
    "- Design and implement a simple CNN model\n",
    "- Train, validate, and evaluate a CNN for binary classification\n",
    "- Analyze model performance using accuracy and loss metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78d33ae",
   "metadata": {},
   "source": [
    "## Part 1: Data Preparation and Setup\n",
    "\n",
    "In this section, we will:\n",
    "1. Install required libraries\n",
    "2. Load the image dataset\n",
    "3. Preprocess images (resize to 128×128 and normalize)\n",
    "4. Split data into training and validation sets (80/20 split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "082276be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n",
      "GPU Available: []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Import Required Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7804c4f",
   "metadata": {},
   "source": [
    "### Step 1: Create Dataset Structure\n",
    "\n",
    "If you don't have a dataset, you can:\n",
    "- Download sample images from an open-source repository\n",
    "- Create synthetic data\n",
    "- Use a pre-existing dataset\n",
    "\n",
    "**Expected folder structure:**\n",
    "```\n",
    "dataset/\n",
    "├── pen/\n",
    "│   ├── pen1.jpg\n",
    "│   ├── pen2.jpg\n",
    "│   └── ...\n",
    "└── pencil/\n",
    "    ├── pencil1.jpg\n",
    "    ├── pencil2.jpg\n",
    "    └── ...\n",
    "```\n",
    "\n",
    "For this demonstration, we'll create a function to load images from your dataset directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "300959ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATASET_PATH = \"dataset\"  # Change this to your dataset directory\n",
    "IMAGE_SIZE = 128\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 15\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "# Create sample dataset structure (for demonstration)\n",
    "# If you have your own dataset, modify DATASET_PATH accordingly\n",
    "def create_sample_dataset_structure():\n",
    "    \"\"\"Create sample folder structure for dataset\"\"\"\n",
    "    os.makedirs(os.path.join(DATASET_PATH, \"pen\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(DATASET_PATH, \"pencil\"), exist_ok=True)\n",
    "    print(f\"Dataset structure created at: {DATASET_PATH}\")\n",
    "\n",
    "# Uncomment the line below if you need to create folder structure\n",
    "# create_sample_dataset_structure()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478f6772",
   "metadata": {},
   "source": [
    "### Step 2: Load and Preprocess Images\n",
    "\n",
    "We'll create functions to:\n",
    "- Load images from directories\n",
    "- Resize to 128×128 pixels\n",
    "- Normalize pixel values to [0, 1]\n",
    "- Create labels for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ec43b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Directory dataset\\pen does not exist\n",
      "Warning: Directory dataset\\pencil does not exist\n",
      "\n",
      "Total images loaded: 0\n",
      "Pen images: 0\n",
      "Pencil images: 0\n",
      "Image shape: No images\n"
     ]
    }
   ],
   "source": [
    "def load_images_from_directory(directory, label, target_size=(IMAGE_SIZE, IMAGE_SIZE)):\n",
    "    \"\"\"\n",
    "    Load images from a directory and return arrays of images and labels\n",
    "    \n",
    "    Parameters:\n",
    "    - directory: path to folder containing images\n",
    "    - label: binary label (0 for pen, 1 for pencil)\n",
    "    - target_size: size to resize images to\n",
    "    \n",
    "    Returns:\n",
    "    - images: array of preprocessed images\n",
    "    - labels: array of corresponding labels\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    # Check if directory exists\n",
    "    if not os.path.exists(directory):\n",
    "        print(f\"Warning: Directory {directory} does not exist\")\n",
    "        return np.array(images), np.array(labels)\n",
    "    \n",
    "    # Get list of image files\n",
    "    image_files = [f for f in os.listdir(directory) \n",
    "                   if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.gif'))]\n",
    "    \n",
    "    print(f\"Loading {len(image_files)} images from {directory}...\")\n",
    "    \n",
    "    for img_file in tqdm(image_files):\n",
    "        try:\n",
    "            img_path = os.path.join(directory, img_file)\n",
    "            # Load and resize image\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is not None:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "                img = cv2.resize(img, target_size)\n",
    "                # Normalize pixel values to [0, 1]\n",
    "                img = img.astype('float32') / 255.0\n",
    "                images.append(img)\n",
    "                labels.append(label)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {img_file}: {str(e)}\")\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Load pen images (label = 0)\n",
    "pen_images, pen_labels = load_images_from_directory(\n",
    "    os.path.join(DATASET_PATH, \"pen\"), \n",
    "    label=0\n",
    ")\n",
    "\n",
    "# Load pencil images (label = 1)\n",
    "pencil_images, pencil_labels = load_images_from_directory(\n",
    "    os.path.join(DATASET_PATH, \"pencil\"), \n",
    "    label=1\n",
    ")\n",
    "\n",
    "# Combine all images and labels\n",
    "all_images = np.concatenate([pen_images, pencil_images])\n",
    "all_labels = np.concatenate([pen_labels, pencil_labels])\n",
    "\n",
    "print(f\"\\nTotal images loaded: {len(all_images)}\")\n",
    "print(f\"Pen images: {len(pen_images)}\")\n",
    "print(f\"Pencil images: {len(pencil_images)}\")\n",
    "print(f\"Image shape: {all_images[0].shape if len(all_images) > 0 else 'No images'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b3b509",
   "metadata": {},
   "source": [
    "### Step 3: Split Dataset into Training and Validation Sets\n",
    "\n",
    "We'll split the data with:\n",
    "- 80% for training\n",
    "- 20% for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a93d733",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Split data into training and validation sets (80/20)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X_train, X_val, y_train, y_val \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[0;32m      3\u001b[0m     all_images, \n\u001b[0;32m      4\u001b[0m     all_labels, \n\u001b[0;32m      5\u001b[0m     test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, \n\u001b[0;32m      6\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, \n\u001b[0;32m      7\u001b[0m     stratify\u001b[38;5;241m=\u001b[39mall_labels\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining set: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X_train)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m images\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation set: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X_val)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m images\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2851\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2848\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[0;32m   2850\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m-> 2851\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2852\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[0;32m   2853\u001b[0m )\n\u001b[0;32m   2855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m   2856\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2481\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2478\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[0;32m   2480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2481\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2482\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2483\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2484\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[0;32m   2485\u001b[0m     )\n\u001b[0;32m   2487\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "# Split data into training and validation sets (80/20)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    all_images, \n",
    "    all_labels, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=all_labels\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_train)} images\")\n",
    "print(f\"Validation set: {len(X_val)} images\")\n",
    "print(f\"\\nTraining labels - Pen: {np.sum(y_train == 0)}, Pencil: {np.sum(y_train == 1)}\")\n",
    "print(f\"Validation labels - Pen: {np.sum(y_val == 0)}, Pencil: {np.sum(y_val == 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e50818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images from the dataset\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "fig.suptitle('Sample Images from Dataset', fontsize=16, fontweight='bold')\n",
    "\n",
    "class_names = ['Pen', 'Pencil']\n",
    "\n",
    "# Show 3 pen images and 3 pencil images\n",
    "for i in range(3):\n",
    "    pen_idx = np.where(y_train == 0)[0][i] if np.sum(y_train == 0) > i else 0\n",
    "    pencil_idx = np.where(y_train == 1)[0][i] if np.sum(y_train == 1) > i else 0\n",
    "    \n",
    "    axes[0, i].imshow(X_train[pen_idx])\n",
    "    axes[0, i].set_title(f'{class_names[0]} (Sample {i+1})')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    axes[1, i].imshow(X_train[pencil_idx])\n",
    "    axes[1, i].set_title(f'{class_names[1]} (Sample {i+1})')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Dataset preparation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377bea5f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: CNN Model Design\n",
    "\n",
    "We'll build a Convolutional Neural Network with the following architecture:\n",
    "\n",
    "- **Input Layer:** 128 × 128 × 3\n",
    "- **Convolution Layer 1:** 32 filters, 3×3 kernel + ReLU activation\n",
    "- **Max Pooling Layer 1:** 2×2 pool size\n",
    "- **Convolution Layer 2:** 64 filters, 3×3 kernel + ReLU activation\n",
    "- **Max Pooling Layer 2:** 2×2 pool size\n",
    "- **Flatten Layer:** Convert 2D feature maps to 1D vector\n",
    "- **Dense Layer (Fully Connected):** 128 units + ReLU activation\n",
    "- **Dropout Layer:** 0.5 dropout rate (regularization)\n",
    "- **Output Layer:** 1 unit with Sigmoid activation (binary classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4919a0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the CNN Model\n",
    "def create_cnn_model(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)):\n",
    "    \"\"\"\n",
    "    Create a CNN model for binary classification (Pen vs Pencil)\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        # First Convolution Block\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # Second Convolution Block\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # Third Convolution Block (Additional for better feature extraction)\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # Flatten Layer\n",
    "        layers.Flatten(),\n",
    "        \n",
    "        # Fully Connected Layers\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.5),  # Regularization to prevent overfitting\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        # Output Layer for Binary Classification\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "model = create_cnn_model()\n",
    "\n",
    "# Display model architecture\n",
    "print(\"=\" * 60)\n",
    "print(\"CNN MODEL ARCHITECTURE\")\n",
    "print(\"=\" * 60)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b5b51e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Model Compilation and Training\n",
    "\n",
    "We'll compile the model with:\n",
    "- **Optimizer:** Adam (adaptive learning rate optimizer)\n",
    "- **Loss Function:** Binary Crossentropy (for binary classification)\n",
    "- **Metric:** Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ece10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"Model compiled successfully!\")\n",
    "print(f\"Optimizer: Adam\")\n",
    "print(f\"Loss Function: Binary Crossentropy\")\n",
    "print(f\"Metrics: Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a216a4db",
   "metadata": {},
   "source": [
    "### Train the Model\n",
    "\n",
    "The model will be trained for 15 epochs with:\n",
    "- Batch size: 32\n",
    "- Validation split: 20% of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd8dbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we have data to train\n",
    "if len(X_train) > 0:\n",
    "    # Train the model\n",
    "    print(\"Training the CNN model...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=(X_val, y_val),\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"Training completed!\")\n",
    "else:\n",
    "    print(\"No training data available. Please add images to the dataset folder.\")\n",
    "    history = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517b4759",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Model Evaluation and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1475245e",
   "metadata": {},
   "source": [
    "### Plot Training and Validation Metrics\n",
    "\n",
    "Visualize the training and validation accuracy and loss over epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78de1332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation accuracy and loss\n",
    "if history is not None:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Plot Accuracy\n",
    "    axes[0].plot(history.history['accuracy'], label='Training Accuracy', linewidth=2)\n",
    "    axes[0].plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
    "    axes[0].set_title('Model Accuracy Over Epochs', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[0].set_ylabel('Accuracy', fontsize=12)\n",
    "    axes[0].legend(fontsize=11)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot Loss\n",
    "    axes[1].plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
    "    axes[1].plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "    axes[1].set_title('Model Loss Over Epochs', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[1].set_ylabel('Loss', fontsize=12)\n",
    "    axes[1].legend(fontsize=11)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Training and validation metrics plotted successfully!\")\n",
    "else:\n",
    "    print(\"No training history available. Train the model first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b566c4",
   "metadata": {},
   "source": [
    "### Evaluate Model Performance on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaac71d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on validation set\n",
    "if len(X_val) > 0:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"MODEL EVALUATION ON VALIDATION SET\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "    \n",
    "    print(f\"\\nValidation Loss: {val_loss:.4f}\")\n",
    "    print(f\"Validation Accuracy: {val_accuracy:.4f} ({val_accuracy*100:.2f}%)\")\n",
    "    print(\"=\" * 60)\n",
    "else:\n",
    "    print(\"No validation data available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35665e6d",
   "metadata": {},
   "source": [
    "### Make Predictions on Sample Images\n",
    "\n",
    "Generate predictions for sample validation images with confidence scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b308b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on sample validation images\n",
    "if len(X_val) > 0:\n",
    "    # Get predictions for all validation images\n",
    "    predictions = model.predict(X_val)\n",
    "    \n",
    "    # Display 12 sample predictions\n",
    "    num_samples = min(12, len(X_val))\n",
    "    fig, axes = plt.subplots(3, 4, figsize=(15, 10))\n",
    "    fig.suptitle('Sample Predictions with Confidence Scores', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    class_names = ['Pen', 'Pencil']\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        ax = axes[i // 4, i % 4]\n",
    "        ax.imshow(X_val[i])\n",
    "        \n",
    "        # Get prediction\n",
    "        pred_prob = predictions[i][0]\n",
    "        pred_class = 1 if pred_prob > 0.5 else 0\n",
    "        confidence = max(pred_prob, 1 - pred_prob) * 100\n",
    "        true_class = int(y_val[i])\n",
    "        \n",
    "        # Color: green if correct, red if incorrect\n",
    "        color = 'green' if pred_class == true_class else 'red'\n",
    "        \n",
    "        title = f\"Pred: {class_names[pred_class]}\\n\"\n",
    "        title += f\"Conf: {confidence:.1f}%\\n\"\n",
    "        title += f\"True: {class_names[true_class]}\"\n",
    "        \n",
    "        ax.set_title(title, fontsize=10, color=color, fontweight='bold')\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate and display accuracy on these samples\n",
    "    correct_predictions = np.sum([int(y_val[i] == (1 if predictions[i][0] > 0.5 else 0)) \n",
    "                                   for i in range(num_samples)])\n",
    "    print(f\"\\nCorrect predictions (sample): {correct_predictions}/{num_samples}\")\n",
    "else:\n",
    "    print(\"No validation data available for predictions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccf61ae",
   "metadata": {},
   "source": [
    "### Identify and Analyze Misclassified Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bedc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze misclassified images\n",
    "if len(X_val) > 0 and len(predictions) > 0:\n",
    "    # Find misclassified images\n",
    "    misclassified_indices = []\n",
    "    for i in range(len(predictions)):\n",
    "        pred_class = 1 if predictions[i][0] > 0.5 else 0\n",
    "        true_class = int(y_val[i])\n",
    "        if pred_class != true_class:\n",
    "            misclassified_indices.append(i)\n",
    "    \n",
    "    print(f\"Total misclassified images: {len(misclassified_indices)}\")\n",
    "    print(f\"Misclassification rate: {(len(misclassified_indices)/len(predictions))*100:.2f}%\")\n",
    "    \n",
    "    if len(misclassified_indices) > 0:\n",
    "        # Display up to 8 misclassified images\n",
    "        num_to_show = min(8, len(misclassified_indices))\n",
    "        fig, axes = plt.subplots(2, 4, figsize=(15, 8))\n",
    "        fig.suptitle('Misclassified Images Analysis', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        for i in range(num_to_show):\n",
    "            idx = misclassified_indices[i]\n",
    "            ax = axes[i // 4, i % 4]\n",
    "            ax.imshow(X_val[idx])\n",
    "            \n",
    "            pred_prob = predictions[idx][0]\n",
    "            pred_class = 1 if pred_prob > 0.5 else 0\n",
    "            true_class = int(y_val[idx])\n",
    "            \n",
    "            title = f\"Pred: {class_names[pred_class]} ({pred_prob*100:.1f}%)\\n\"\n",
    "            title += f\"True: {class_names[true_class]}\"\n",
    "            \n",
    "            ax.set_title(title, fontsize=10, fontweight='bold', color='red')\n",
    "            ax.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"POSSIBLE REASONS FOR MISCLASSIFICATION:\")\n",
    "        print(\"=\" * 60)\n",
    "        print(\"1. Similar appearance between pen and pencil in certain lighting\")\n",
    "        print(\"2. Images with poor quality or extreme angles\")\n",
    "        print(\"3. Insufficient training data for diverse object variations\")\n",
    "        print(\"4. Similar colors or textures causing confusion\")\n",
    "        print(\"5. Need for more epochs or model architecture improvement\")\n",
    "        print(\"=\" * 60)\n",
    "    else:\n",
    "        print(\"No misclassified images found! Model is performing perfectly.\")\n",
    "else:\n",
    "    print(\"Unable to analyze misclassifications. Run predictions first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5bf48e",
   "metadata": {},
   "source": [
    "### Generate Performance Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112aaae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and display comprehensive performance report\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\" \" * 15 + \"CNN MODEL PERFORMANCE SUMMARY REPORT\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n1. DATASET INFORMATION:\")\n",
    "print(f\"   - Total images: {len(all_images)}\")\n",
    "print(f\"   - Training images: {len(X_train)} (80%)\")\n",
    "print(f\"   - Validation images: {len(X_val)} (20%)\")\n",
    "print(f\"   - Image size: {IMAGE_SIZE} × {IMAGE_SIZE} × 3\")\n",
    "\n",
    "print(\"\\n2. CLASS DISTRIBUTION:\")\n",
    "print(f\"   - Pen images: {np.sum(y_train == 0)} (train) + {np.sum(y_val == 0)} (val)\")\n",
    "print(f\"   - Pencil images: {np.sum(y_train == 1)} (train) + {np.sum(y_val == 1)} (val)\")\n",
    "\n",
    "print(\"\\n3. MODEL ARCHITECTURE:\")\n",
    "print(f\"   - Total trainable parameters: {model.count_params():,}\")\n",
    "print(\"   - Architecture: 3 Convolution blocks + 2 Dense layers\")\n",
    "\n",
    "if history is not None:\n",
    "    print(\"\\n4. TRAINING METRICS:\")\n",
    "    print(f\"   - Epochs: {len(history.history['loss'])}\")\n",
    "    print(f\"   - Initial training accuracy: {history.history['accuracy'][0]*100:.2f}%\")\n",
    "    print(f\"   - Final training accuracy: {history.history['accuracy'][-1]*100:.2f}%\")\n",
    "    print(f\"   - Final validation accuracy: {history.history['val_accuracy'][-1]*100:.2f}%\")\n",
    "    \n",
    "    if len(X_val) > 0:\n",
    "        val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "        print(f\"\\n5. VALIDATION RESULTS:\")\n",
    "        print(f\"   - Validation Loss: {val_loss:.4f}\")\n",
    "        print(f\"   - Validation Accuracy: {val_accuracy*100:.2f}%\")\n",
    "        \n",
    "        if len(predictions) > 0:\n",
    "            misclassified = len([i for i in range(len(predictions)) \n",
    "                                 if int(y_val[i]) != (1 if predictions[i][0] > 0.5 else 0)])\n",
    "            print(f\"   - Misclassified images: {misclassified}/{len(X_val)}\")\n",
    "            print(f\"   - Error rate: {(misclassified/len(X_val))*100:.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f5fd7e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Model Persistence: Save and Load the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f5ec72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model_save_path = \"pen_pencil_classifier_model.h5\"\n",
    "model.save(model_save_path)\n",
    "print(f\"Model saved successfully to: {model_save_path}\")\n",
    "\n",
    "# Function to load the saved model\n",
    "def load_trained_model(model_path):\n",
    "    \"\"\"Load a previously trained model\"\"\"\n",
    "    return keras.models.load_model(model_path)\n",
    "\n",
    "# Example: Load the model (commented out)\n",
    "# loaded_model = load_trained_model(model_save_path)\n",
    "# print(f\"Model loaded successfully from: {model_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0591746",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Reflection and Discussion\n",
    "\n",
    "### Key Learnings:\n",
    "\n",
    "1. **Image Preprocessing**: The importance of normalizing and resizing images to a consistent format\n",
    "2. **Model Architecture**: How convolutional layers extract features and pooling layers reduce dimensionality\n",
    "3. **Overfitting Prevention**: The role of dropout and validation monitoring\n",
    "4. **Performance Metrics**: Interpreting accuracy and loss to understand model behavior\n",
    "\n",
    "### Challenges Encountered:\n",
    "\n",
    "- **Challenge 1**: Achieving high accuracy on diverse image variations\n",
    "  - *Solution*: Include diverse training data with different angles, lighting, and backgrounds\n",
    "  \n",
    "- **Challenge 2**: Model overfitting when training data is limited\n",
    "  - *Solution*: Apply dropout regularization and data augmentation techniques\n",
    "  \n",
    "- **Challenge 3**: Misclassification due to similar features between classes\n",
    "  - *Solution*: Collect more distinct examples and improve model architecture\n",
    "\n",
    "### Future Improvements:\n",
    "\n",
    "1. **Data Augmentation**: Apply rotation, flipping, and brightness adjustments to training data\n",
    "2. **Transfer Learning**: Use pre-trained models (VGG16, ResNet50) for better performance\n",
    "3. **Hyperparameter Tuning**: Optimize learning rate, batch size, and number of filters\n",
    "4. **Class Imbalance**: Use weighted loss if dataset has imbalanced classes\n",
    "5. **Real-world Testing**: Test on live camera feed using OpenCV\n",
    "\n",
    "### Conclusion:\n",
    "\n",
    "This activity demonstrates the complete pipeline of building, training, and evaluating a CNN for binary image classification. The model successfully learned to distinguish between pens and pencils, and the analysis of misclassifications provides insights for further improvement."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
